<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="description" content=""> <meta name="keywords" content=""> <meta name="viewport" content="width=device-width, initial-scale=1"> <title>Zolly: Zoom Focal Length Correctly for Perspective-Distorted Human Mesh Reconstruction <br> <font size=6 color=#E1001E>ICCV 2023 Oral</font></title> <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet"> <link rel="stylesheet" href="/assets/css/nerfies_css/bulma.min.css"> <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css"/> <link rel="stylesheet" href="/assets/css/nerfies_css/index.css"> <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script> <script defer src="/assets/js/nerfies_js/fontawesome.all.min.js"></script> <script src="/assets/js/nerfies_js/index.js"></script> <script src="/assets/js/twentytwenty_js/jquery.event.move.js" type="text/javascript"></script> <script src="/assets/js/twentytwenty_js/jquery.twentytwenty.js" type="text/javascript"></script> <link rel="stylesheet" href="/assets/css/twentytwenty.css"> </head> <body> <nav class="navbar" role="navigation" aria-label="main navigation"> <div class="navbar-brand"> <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false"> <span aria-hidden="true"></span> <span aria-hidden="true"></span> <span aria-hidden="true"></span> </a> </div> <div class="navbar-menu"> <div class="navbar-start" style="flex-grow: 1; justify-content: center;"> <a class="navbar-item" href="https://yongtaoge.github.io"> <span class="icon"> <i class="fas fa-home"></i> </span> </a> <div class="navbar-item has-dropdown is-hoverable"> <a class="navbar-link"> More Research </a> <div class="navbar-dropdown"> <a class="navbar-item" href="https://yongtaoge.github.io/projects/humanwild"> HumanFlow </a> <a class="navbar-item" href="https://yongtaoge.github.io/projects/poseur"> Poseur </a> </div> </div> </div> </div> </nav> <section class="hero"> <div class="hero-body"> <div class="container is-max-desktop"> <div class="columns is-centered"> <div class="column has-text-centered"> <h1 class="title is-1 publication-title">Zolly: Zoom Focal Length Correctly for Perspective-Distorted Human Mesh Reconstruction <br> <font size="6" color="#E1001E">ICCV 2023 Oral</font> </h1> <div class="is-size-5 publication-authors"> <span class="author-block"> <a href="https://wenjiawang0312.github.io/" target="_blank" rel="noopener noreferrer">Wenjia Wang</a><sup>3</sup>    <a href="https://yongtaoge.github.io/" target="_blank">Yongtao Ge</a><sup>1,2</sup>    <a href="https://scholar.google.com/citations?user=TOZ9wR4AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Haiyi Mei</a><sup>1,2</sup>    <a href="https://caizhongang.github.io/" target="_blank" rel="noopener noreferrer">Zhongang Cai</a><sup>1,2</sup>    <a target="_blank">Qingping Sun</a><sup>1,2</sup>    <a href="http://yanglei.me/" target="_blank" rel="noopener noreferrer">Chunhua Shen</a><sup>2</sup>    <a href="https://yongtaoge.github.io/" target="_blank">Lei Yang</a><sup>1,2</sup>    <a href="https://i.cs.hku.hk/~taku/" target="_blank" rel="noopener noreferrer">Taku Komura</a><sup>1,2</sup>    </span> </div> <div class="is-size-5 publication-authors"> <span class="author-block"> <sup>1</sup>The University of Hongkong    <sup>2</sup>The Univerity of Adelaide    <sup>3</sup>Shanghai AI Laboratory    <br><sup>4</sup>SenseTime Research    <sup>5</sup>Zhejiang University    </span> </div> <div class="column has-text-centered"> <div class="publication-links"> <span class="link-block"> <a href="https://www.cs.virginia.edu/~robins/Turing_Paper_1936.pdf" class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer"> <span class="icon"> <i class="fas fa-file-pdf"></i> </span> <span>Paper</span> </a> </span> <span class="link-block"> <a href="https://www.youtube.com/results?search_query=turing+machine" class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer"> <span class="icon"> <i class="fab fa-youtube"></i> </span> <span>Video</span> </a> </span> <span class="link-block"> <a href="https://github.com/topics/turing-machines" class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer"> <span class="icon"> <i class="fab fa-github"></i> </span> <span>Code</span> </a> </span> <span class="link-block"> <a href="https://huggingface.co/docs/datasets" class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer"> <span class="icon"> <i class="fas fa-database"></i> </span> <span>Data</span> </a> </span> </div> </div> </div> </div> </div> </div> </section> <section class="section"> <div class="container is-max-desktop"> <div class="content"> <div class="columns is-centered has-text-centered"> <div class="column is-four-fifths"> <h2>Abstract</h2> <div class="content has-text-justified"> As it is hard to calibrate single-view RGB images in the wild, existing 3D human mesh reconstruction (3DHMR) methods either use a constant large focal length or estimate one based on the background environment context, which can not tackle the problem of the torso, limb, hand or face distortion caused by perspective camera projection when the camera is close to the human body. The naive focal length assumptions can harm this task with the incorrectly formulated projection matrices. To solve this, we propose Zolly, the first 3DHMR method focusing on perspective-distorted images. Our approach begins with analysing the reason for perspective distortion, which we find is mainly caused by the relative location of the human body to the camera center. We propose a new camera model and a novel 2D representation, termed distortion image, which describes the 2D dense distortion scale of the human body. We then estimate the distance from distortion scale features rather than environment context features. Afterwards, We integrate the distortion feature with image features to reconstruct the body mesh. To formulate the correct projection matrix and locate the human body position, we simultaneously use perspective and weak-perspective projection loss. Since existing datasets could not handle this task, we propose the first synthetic dataset PDHuman and extend two real-world datasets tailored for this task, all containing perspective-distorted human images. Extensive experiments show that Zolly outperforms existing state-of-the-art methods on both perspective-distorted datasets and the standard benchmark (3DPW). </div> </div> </div> <hr> <blockquote> <p>Note: Please ref to this <a href="https://wenjiawang0312.github.io/projects/zolly/" target="_blank" rel="noopener noreferrer">project link</a>. for more details.</p> </blockquote> <h2 id="proposed-dataset">Proposed Dataset</h2> <p>PDHuman dataset is rendered based on the pipeline of <a href="https://github.com/openxrlab/xrfeitoria" target="_blank" rel="noopener noreferrer noopener noreferrer">XRFeitoria</a>.</p> <h2 id="citation">Citation</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{wang2023zolly,
  author    = {Wang, Wenjia and Ge, Yongtao and Mei, Haiyi and Cai, Zhongang and Sun, Qingping and Wang, Yanjun and Shen, Chunhua and Yang, Lei and Komura, Taku},
  title     = {Zolly: Zoom Focal Length Correctly for Perspective-Distorted Human Mesh Reconstruction},
  journal   = {ICCV},
  year      = {2023},
}

</code></pre></div></div> </div> </div> </section> <footer class="footer"> <div class="container"> <div class="columns is-centered"> <div class="column is-8"> <div class="content"> <p> Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io" target="_blank" rel="noopener noreferrer">NeRFies</a>. </p> </div> </div> </div> </div> </footer> </body> </html>